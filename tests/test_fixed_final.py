#!/usr/bin/env python3
"""
Final test for the fixed LFM2-VL captioning with proper context handling.
"""

import sys
import os
import logging
from pathlib import Path

# Add src to path
sys.path.append('src')

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_fixed_captioning():
    """Test the fixed captioning implementation."""
    logger.info("üß™ Testing fixed LFM2-VL captioning with proper context...")
    
    try:
        from src.pipeline import VideoContextCaptionPipeline
        
        # Initialize pipeline
        logger.info("Loading LFM2-VL-450M model...")
        pipeline = VideoContextCaptionPipeline(
            model_path='/home/frank/BrandInfluencerDatasetTraining/LFM2-VL-450M',
            device='cuda',
            max_frames=3,
            frame_extraction_strategy='key_frames'
        )
        
        # Check if we're using the actual model
        if pipeline.liquid_integration.model.get('is_mock', True):
            logger.warning("‚ö†Ô∏è Using mock model instead of actual LFM model!")
            return None
        
        logger.info("‚úÖ Actual LFM2-VL model loaded successfully")
        
        # Test with sample image
        sample_image_path = 'examples/sample_image.jpg'
        
        if not Path(sample_image_path).exists():
            logger.error(f"Sample image not found: {sample_image_path}")
            return None
        
        logger.info(f"Using sample image: {sample_image_path}")
        
        # Test 1: Image captioning without context
        logger.info("Testing image captioning without video context...")
        result_no_context = pipeline.image_captioner.generate_caption_without_context(
            image_path=sample_image_path
        )
        
        print("\n" + "="*70)
        print("üì∏ IMAGE CAPTIONING (Without Context)")
        print("="*70)
        print(f"Caption: {result_no_context['caption']}")
        print(f"Confidence: {result_no_context['confidence']:.2f}")
        print(f"Processing Time: {result_no_context['processing_time']:.2f}s")
        
        # Test 2: Video-context captioning
        sample_video_path = 'examples/sample_video.mp4'
        
        if Path(sample_video_path).exists():
            logger.info("Testing image captioning with video context...")
            result_with_context = pipeline.generate_caption(
                image_path=sample_image_path,
                video_path=sample_video_path,
                context_weight=0.7
            )
            
            print("\n" + "="*70)
            print("üé¨ VIDEO-CONTEXT CAPTIONING")
            print("="*70)
            print(f"Caption: {result_with_context['caption']}")
            print(f"Confidence: {result_with_context['confidence']:.2f}")
            print(f"Context Relevance: {result_with_context['context_relevance']:.2f}")
            print(f"Frames Processed: {result_with_context['frames_processed']}")
            print(f"Processing Time: {result_with_context['processing_time']:.2f}s")
            
            # Show video context details
            if 'video_context' in result_with_context:
                video_context = result_with_context['video_context']
                print(f"\nüìπ VIDEO CONTEXT DETAILS:")
                print(f"   Context Text: {video_context.get('context_text', 'N/A')[:200]}...")
                print(f"   Frames Processed: {video_context.get('frames_processed', 'N/A')}")
                print(f"   Temporal Consistency: {video_context.get('temporal_consistency', 'N/A'):.3f}")
                
                # Show individual frame captions
                if 'frame_captions' in video_context:
                    print(f"\n   Individual Frame Captions:")
                    for i, caption in enumerate(video_context['frame_captions']):
                        print(f"     Frame {i+1}: {caption[:100]}...")
        else:
            logger.warning(f"Sample video not found: {sample_video_path}")
            result_with_context = None
        
        return {
            'no_context': result_no_context,
            'with_context': result_with_context
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in fixed captioning test: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main test function."""
    print("üß™ LFM2-VL Fixed Captioning Test - Final")
    print("=" * 70)
    print("Testing with proper chat template, context handling, and text decoding")
    print("=" * 70)
    
    results = test_fixed_captioning()
    
    if results:
        print("\n" + "="*70)
        print("üìä TEST RESULTS")
        print("="*70)
        
        print("‚úÖ Image captioning (without context): SUCCESS")
        print(f"   Caption: {results['no_context']['caption']}")
        
        if results['with_context']:
            print("‚úÖ Video-context captioning: SUCCESS")
            print(f"   Caption: {results['with_context']['caption']}")
            print(f"   Context Relevance: {results['with_context']['context_relevance']:.3f}")
        else:
            print("‚ùå Video-context captioning: SKIPPED (no video)")
        
        print("\n‚úÖ All fixes applied successfully!")
        print("‚úÖ No more garbled text or array outputs!")
        print("‚úÖ Proper context integration working!")
    else:
        print("\n‚ùå Test failed - check logs for details")
    
    print("\nüéâ Fixed captioning test completed!")

if __name__ == "__main__":
    main()
